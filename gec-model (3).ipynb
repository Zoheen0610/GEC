{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-12T08:40:56.700180Z","iopub.execute_input":"2025-04-12T08:40:56.700444Z","iopub.status.idle":"2025-04-12T08:40:57.097110Z","shell.execute_reply.started":"2025-04-12T08:40:56.700424Z","shell.execute_reply":"2025-04-12T08:40:57.096481Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!pip install transformers datasets sacrebleu sentencepiece\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T08:40:57.098147Z","iopub.execute_input":"2025-04-12T08:40:57.098507Z","iopub.status.idle":"2025-04-12T08:41:01.723468Z","shell.execute_reply.started":"2025-04-12T08:40:57.098480Z","shell.execute_reply":"2025-04-12T08:41:01.722390Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.3.1)\nCollecting sacrebleu\n  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.2.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.12)\nCollecting portalocker (from sacrebleu)\n  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\nRequirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (5.3.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading portalocker-3.1.1-py3-none-any.whl (19 kB)\nInstalling collected packages: portalocker, sacrebleu\nSuccessfully installed portalocker-3.1.1 sacrebleu-2.5.1\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from datasets import load_dataset, Dataset\n\ndataset = load_dataset(\"juancavallotti/multilingual-gec\")\n\nprint(\"datasetdict looks like:\",dataset)\n\n# Keep only relevant columns for eng\ntrain_dataset = dataset[\"train\"].filter(lambda example: example[\"lang\"] == \"en\")\ntrain_dataset = train_dataset.remove_columns([\"transformation\", \"sec_transformation\", \"__index_level_0__\"])\n\nprint(train_dataset[0:5])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T08:41:01.725639Z","iopub.execute_input":"2025-04-12T08:41:01.725912Z","iopub.status.idle":"2025-04-12T08:41:09.705059Z","shell.execute_reply.started":"2025-04-12T08:41:01.725888Z","shell.execute_reply":"2025-04-12T08:41:09.704209Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/2.98k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ffa391438f8460fa6320b71bc89546c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"dataset_infos.json:   0%|          | 0.00/1.04k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5fbc14896df471d9933492b10e0b91d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/31.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c982cef37134bb1aa79e0ad1a0689ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/332k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b40a0e8e62a2444f8ad7c3a9766280f2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/216318 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82c96f4a9b804931bf55cf71d492cf53"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/2186 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83903ac52dfa40209815739ccb9504f8"}},"metadata":{}},{"name":"stdout","text":"datasetdict looks like: DatasetDict({\n    train: Dataset({\n        features: ['lang', 'sentence', 'modified', 'transformation', 'sec_transformation', '__index_level_0__'],\n        num_rows: 216318\n    })\n    test: Dataset({\n        features: ['lang', 'sentence', 'modified', 'transformation', 'sec_transformation', '__index_level_0__'],\n        num_rows: 2186\n    })\n})\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/216318 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9ca5c7a191447959e92b65edd2e26de"}},"metadata":{}},{"name":"stdout","text":"{'lang': ['en', 'en', 'en', 'en', 'en'], 'sentence': ['Plants, obviously, cannot move after they have put down roots.', 'I looked at the schedule.', \"It's very hard to get rid of bad habits.\", \"Anyway, I think I've said enough.\", 'Technologies allow you to do more things.'], 'modified': [\"fix grammar: Plants, obviously, cannot moved after they hadn't put down roots.\", 'fix grammar: I looked at schedule.', 'fix grammar: It am very hard to get rid of bad habits.', \"fix grammar: Anyway, think I've said enough.\", 'fix grammar: Technologies allow you to do most things.']}\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"processed_data = {\n    \"input_text\": train_dataset[\"modified\"],\n    \"target_text\": train_dataset[\"sentence\"]\n}\n\n\n# Convert to Hugging Face Dataset format\nformatted_dataset = Dataset.from_dict(processed_data)\n\n\nfor i in range(5):  \n    print(f\"Example {i+1}:\")\n    print(f\"  Input: {formatted_dataset['input_text'][i]}\")\n    print(f\"  Target: {formatted_dataset['target_text'][i]}\")\n    print(\"-\" * 50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T08:41:09.706316Z","iopub.execute_input":"2025-04-12T08:41:09.706718Z","iopub.status.idle":"2025-04-12T08:41:10.875508Z","shell.execute_reply.started":"2025-04-12T08:41:09.706696Z","shell.execute_reply":"2025-04-12T08:41:10.874786Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Example 1:\n  Input: fix grammar: Plants, obviously, cannot moved after they hadn't put down roots.\n  Target: Plants, obviously, cannot move after they have put down roots.\n--------------------------------------------------\nExample 2:\n  Input: fix grammar: I looked at schedule.\n  Target: I looked at the schedule.\n--------------------------------------------------\nExample 3:\n  Input: fix grammar: It am very hard to get rid of bad habits.\n  Target: It's very hard to get rid of bad habits.\n--------------------------------------------------\nExample 4:\n  Input: fix grammar: Anyway, think I've said enough.\n  Target: Anyway, I think I've said enough.\n--------------------------------------------------\nExample 5:\n  Input: fix grammar: Technologies allow you to do most things.\n  Target: Technologies allow you to do more things.\n--------------------------------------------------\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from transformers import T5Tokenizer, T5ForConditionalGeneration, TrainingArguments, Trainer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T08:41:10.876366Z","iopub.execute_input":"2025-04-12T08:41:10.876612Z","iopub.status.idle":"2025-04-12T08:41:24.541804Z","shell.execute_reply.started":"2025-04-12T08:41:10.876581Z","shell.execute_reply":"2025-04-12T08:41:24.541158Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n\n# Tokenize input and target text\ndef tokenize_function(examples):\n    inputs = tokenizer(examples[\"input_text\"], padding=\"max_length\", truncation=True, max_length=128)\n    targets = tokenizer(examples[\"target_text\"], padding=\"max_length\", truncation=True, max_length=128)\n    \n    return {\n        \"input_ids\": inputs[\"input_ids\"],\n        \"attention_mask\": inputs[\"attention_mask\"],\n        \"labels\": targets[\"input_ids\"]\n    }\n\n\ntokenized_dataset = formatted_dataset.map(tokenize_function, batched=True)\n\nprint(tokenized_dataset[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T08:41:24.542766Z","iopub.execute_input":"2025-04-12T08:41:24.543523Z","iopub.status.idle":"2025-04-12T08:41:43.227894Z","shell.execute_reply.started":"2025-04-12T08:41:24.543485Z","shell.execute_reply":"2025-04-12T08:41:43.227210Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b08f1a987c9844069e13d20301260710"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff651c0bc62846adab9251d6901be2ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a40af6497974df6b7f60afdc77173fa"}},"metadata":{}},{"name":"stderr","text":"You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/50862 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"323f9460db164705b7543644e3140e1d"}},"metadata":{}},{"name":"stdout","text":"{'input_text': \"fix grammar: Plants, obviously, cannot moved after they hadn't put down roots.\", 'target_text': 'Plants, obviously, cannot move after they have put down roots.', 'input_ids': [2210, 19519, 10, 6041, 7, 6, 6865, 6, 1178, 2301, 227, 79, 12381, 31, 17, 474, 323, 8523, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [6041, 7, 6, 6865, 6, 1178, 888, 227, 79, 43, 474, 323, 8523, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_size = int(0.8 * len(tokenized_dataset))\ntrain_dataset = tokenized_dataset.select(range(train_size))\neval_dataset = tokenized_dataset.select(range(train_size, len(tokenized_dataset)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T08:41:43.228688Z","iopub.execute_input":"2025-04-12T08:41:43.228956Z","iopub.status.idle":"2025-04-12T08:41:43.247106Z","shell.execute_reply.started":"2025-04-12T08:41:43.228920Z","shell.execute_reply":"2025-04-12T08:41:43.246320Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"from transformers import  TrainerCallback\n\nmodel = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n\ntraining_args = TrainingArguments(\n    output_dir=\"/kaggle/working/t5-grammar-corrector\",  \n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    num_train_epochs=3,\n    logging_steps=50, \n    save_steps=500,  \n    evaluation_strategy=\"steps\",  \n    eval_steps=500,  \n    save_total_limit=2, \n    fp16=True,\n    report_to=\"none\", \n)\n\n\nclass ProgressCallback(TrainerCallback):\n    def on_log(self, args, state, control, logs=None, **kwargs):\n        if logs:\n            print(f\"Step {state.global_step}: Loss = {logs.get('loss', 'N/A')}, LR = {logs.get('learning_rate', 'N/A')}\", flush=True)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=eval_dataset,\n    callbacks=[ProgressCallback()],\n)\n\n\ntrainer.train()\n\ntrainer.save_model(\"/kaggle/working/t5-grammar-corrector\")\n\nmodel.save_pretrained(\"/kaggle/working/t5-grammar-corrector\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T08:41:43.248958Z","iopub.execute_input":"2025-04-12T08:41:43.249215Z","iopub.status.idle":"2025-04-12T10:59:36.233871Z","shell.execute_reply.started":"2025-04-12T08:41:43.249193Z","shell.execute_reply":"2025-04-12T10:59:36.232871Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58591863e8ff4c82b1137d32689383a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e422e7e9368f467ba2925d46e7f6565b"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\nPassing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='7632' max='7632' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [7632/7632 2:17:40, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.027000</td>\n      <td>0.018151</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.017800</td>\n      <td>0.015229</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.017200</td>\n      <td>0.013195</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.015400</td>\n      <td>0.012304</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.014000</td>\n      <td>0.011244</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.012400</td>\n      <td>0.011037</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>0.011100</td>\n      <td>0.010668</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>0.010700</td>\n      <td>0.010229</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>0.009500</td>\n      <td>0.010147</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>0.011500</td>\n      <td>0.009619</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>0.008800</td>\n      <td>0.009802</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>0.009000</td>\n      <td>0.009601</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>0.008300</td>\n      <td>0.009528</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>0.008300</td>\n      <td>0.009530</td>\n    </tr>\n    <tr>\n      <td>7500</td>\n      <td>0.008900</td>\n      <td>0.009490</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"Step 50: Loss = 3.093, LR = 4.9672431865828094e-05\nStep 100: Loss = 0.1017, LR = 4.9344863731656185e-05\nStep 150: Loss = 0.043, LR = 4.9017295597484283e-05\nStep 200: Loss = 0.0337, LR = 4.8689727463312375e-05\nStep 250: Loss = 0.0284, LR = 4.8362159329140466e-05\nStep 300: Loss = 0.0292, LR = 4.803459119496855e-05\nStep 350: Loss = 0.0258, LR = 4.770702306079665e-05\nStep 400: Loss = 0.0287, LR = 4.737945492662474e-05\nStep 450: Loss = 0.0257, LR = 4.705188679245283e-05\nStep 500: Loss = 0.027, LR = 4.672431865828092e-05\nStep 500: Loss = N/A, LR = N/A\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Step 550: Loss = 0.024, LR = 4.6396750524109015e-05\nStep 600: Loss = 0.0212, LR = 4.606918238993711e-05\nStep 650: Loss = 0.023, LR = 4.5741614255765204e-05\nStep 700: Loss = 0.0205, LR = 4.5414046121593296e-05\nStep 750: Loss = 0.0193, LR = 4.508647798742139e-05\nStep 800: Loss = 0.021, LR = 4.475890985324948e-05\nStep 850: Loss = 0.0179, LR = 4.443134171907757e-05\nStep 900: Loss = 0.0194, LR = 4.410377358490566e-05\nStep 950: Loss = 0.0185, LR = 4.377620545073375e-05\nStep 1000: Loss = 0.0178, LR = 4.3448637316561844e-05\nStep 1000: Loss = N/A, LR = N/A\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Step 1050: Loss = 0.019, LR = 4.312106918238994e-05\nStep 1100: Loss = 0.0185, LR = 4.2793501048218034e-05\nStep 1150: Loss = 0.0175, LR = 4.2465932914046125e-05\nStep 1200: Loss = 0.018, LR = 4.213836477987422e-05\nStep 1250: Loss = 0.0176, LR = 4.181079664570231e-05\nStep 1300: Loss = 0.0163, LR = 4.14832285115304e-05\nStep 1350: Loss = 0.0153, LR = 4.115566037735849e-05\nStep 1400: Loss = 0.0159, LR = 4.082809224318658e-05\nStep 1450: Loss = 0.0191, LR = 4.0500524109014674e-05\nStep 1500: Loss = 0.0172, LR = 4.017295597484277e-05\nStep 1500: Loss = N/A, LR = N/A\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Step 1550: Loss = 0.0164, LR = 3.984538784067086e-05\nStep 1600: Loss = 0.0144, LR = 3.9517819706498955e-05\nStep 1650: Loss = 0.015, LR = 3.9190251572327046e-05\nStep 1700: Loss = 0.0152, LR = 3.886268343815514e-05\nStep 1750: Loss = 0.0157, LR = 3.8535115303983236e-05\nStep 1800: Loss = 0.0144, LR = 3.820754716981133e-05\nStep 1850: Loss = 0.0159, LR = 3.787997903563941e-05\nStep 1900: Loss = 0.0154, LR = 3.75524109014675e-05\nStep 1950: Loss = 0.0163, LR = 3.7224842767295595e-05\nStep 2000: Loss = 0.0154, LR = 3.689727463312369e-05\nStep 2000: Loss = N/A, LR = N/A\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Step 2050: Loss = 0.0188, LR = 3.6569706498951784e-05\nStep 2100: Loss = 0.0138, LR = 3.6242138364779876e-05\nStep 2150: Loss = 0.0142, LR = 3.591457023060797e-05\nStep 2200: Loss = 0.0152, LR = 3.558700209643606e-05\nStep 2250: Loss = 0.0157, LR = 3.525943396226416e-05\nStep 2300: Loss = 0.0145, LR = 3.493186582809225e-05\nStep 2350: Loss = 0.0149, LR = 3.460429769392033e-05\nStep 2400: Loss = 0.0155, LR = 3.4276729559748424e-05\nStep 2450: Loss = 0.0152, LR = 3.394916142557652e-05\nStep 2500: Loss = 0.014, LR = 3.3621593291404614e-05\nStep 2500: Loss = N/A, LR = N/A\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Step 2550: Loss = 0.0149, LR = 3.3294025157232705e-05\nStep 2600: Loss = 0.0116, LR = 3.2966457023060796e-05\nStep 2650: Loss = 0.0115, LR = 3.263888888888889e-05\nStep 2700: Loss = 0.0129, LR = 3.2311320754716986e-05\nStep 2750: Loss = 0.0136, LR = 3.198375262054508e-05\nStep 2800: Loss = 0.0119, LR = 3.165618448637317e-05\nStep 2850: Loss = 0.0115, LR = 3.132861635220126e-05\nStep 2900: Loss = 0.0101, LR = 3.100104821802935e-05\nStep 2950: Loss = 0.0103, LR = 3.067348008385744e-05\nStep 3000: Loss = 0.0124, LR = 3.0345911949685535e-05\nStep 3000: Loss = N/A, LR = N/A\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Step 3050: Loss = 0.0121, LR = 3.0018343815513626e-05\nStep 3100: Loss = 0.0117, LR = 2.969077568134172e-05\nStep 3150: Loss = 0.0117, LR = 2.9363207547169812e-05\nStep 3200: Loss = 0.0118, LR = 2.9035639412997907e-05\nStep 3250: Loss = 0.0111, LR = 2.8708071278826e-05\nStep 3300: Loss = 0.0111, LR = 2.838050314465409e-05\nStep 3350: Loss = 0.0116, LR = 2.8052935010482185e-05\nStep 3400: Loss = 0.0124, LR = 2.7725366876310273e-05\nStep 3450: Loss = 0.0115, LR = 2.7397798742138364e-05\nStep 3500: Loss = 0.0111, LR = 2.7070230607966455e-05\nStep 3500: Loss = N/A, LR = N/A\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Step 3550: Loss = 0.0108, LR = 2.674266247379455e-05\nStep 3600: Loss = 0.0104, LR = 2.641509433962264e-05\nStep 3650: Loss = 0.0107, LR = 2.6087526205450736e-05\nStep 3700: Loss = 0.0113, LR = 2.5759958071278828e-05\nStep 3750: Loss = 0.0116, LR = 2.543238993710692e-05\nStep 3800: Loss = 0.0102, LR = 2.5104821802935014e-05\nStep 3850: Loss = 0.0098, LR = 2.4777253668763102e-05\nStep 3900: Loss = 0.0111, LR = 2.4449685534591197e-05\nStep 3950: Loss = 0.0111, LR = 2.412211740041929e-05\nStep 4000: Loss = 0.0107, LR = 2.3794549266247383e-05\nStep 4000: Loss = N/A, LR = N/A\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Step 4050: Loss = 0.0121, LR = 2.346698113207547e-05\nStep 4100: Loss = 0.009, LR = 2.3139412997903566e-05\nStep 4150: Loss = 0.0104, LR = 2.2811844863731657e-05\nStep 4200: Loss = 0.0108, LR = 2.248427672955975e-05\nStep 4250: Loss = 0.0105, LR = 2.2156708595387844e-05\nStep 4300: Loss = 0.0115, LR = 2.182914046121593e-05\nStep 4350: Loss = 0.0096, LR = 2.1501572327044026e-05\nStep 4400: Loss = 0.0096, LR = 2.1174004192872118e-05\nStep 4450: Loss = 0.0103, LR = 2.0846436058700213e-05\nStep 4500: Loss = 0.0095, LR = 2.0518867924528304e-05\nStep 4500: Loss = N/A, LR = N/A\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Step 4550: Loss = 0.0109, LR = 2.0191299790356395e-05\nStep 4600: Loss = 0.0102, LR = 1.9863731656184487e-05\nStep 4650: Loss = 0.0099, LR = 1.9536163522012578e-05\nStep 4700: Loss = 0.0111, LR = 1.9208595387840673e-05\nStep 4750: Loss = 0.0106, LR = 1.8881027253668765e-05\nStep 4800: Loss = 0.0094, LR = 1.8553459119496856e-05\nStep 4850: Loss = 0.0097, LR = 1.8225890985324947e-05\nStep 4900: Loss = 0.0089, LR = 1.789832285115304e-05\nStep 4950: Loss = 0.0112, LR = 1.7570754716981134e-05\nStep 5000: Loss = 0.0115, LR = 1.7243186582809225e-05\nStep 5000: Loss = N/A, LR = N/A\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Step 5050: Loss = 0.0094, LR = 1.691561844863732e-05\nStep 5100: Loss = 0.0089, LR = 1.6588050314465408e-05\nStep 5150: Loss = 0.0087, LR = 1.6260482180293503e-05\nStep 5200: Loss = 0.0088, LR = 1.5932914046121594e-05\nStep 5250: Loss = 0.0088, LR = 1.5605345911949685e-05\nStep 5300: Loss = 0.008, LR = 1.527777777777778e-05\nStep 5350: Loss = 0.009, LR = 1.495020964360587e-05\nStep 5400: Loss = 0.0087, LR = 1.4622641509433963e-05\nStep 5450: Loss = 0.0095, LR = 1.4295073375262054e-05\nStep 5500: Loss = 0.0088, LR = 1.3967505241090148e-05\nStep 5500: Loss = N/A, LR = N/A\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Step 5550: Loss = 0.0081, LR = 1.363993710691824e-05\nStep 5600: Loss = 0.0075, LR = 1.331236897274633e-05\nStep 5650: Loss = 0.0088, LR = 1.2984800838574423e-05\nStep 5700: Loss = 0.0091, LR = 1.2657232704402517e-05\nStep 5750: Loss = 0.0076, LR = 1.232966457023061e-05\nStep 5800: Loss = 0.0091, LR = 1.2002096436058701e-05\nStep 5850: Loss = 0.0084, LR = 1.1674528301886793e-05\nStep 5900: Loss = 0.0087, LR = 1.1346960167714884e-05\nStep 5950: Loss = 0.0086, LR = 1.1019392033542977e-05\nStep 6000: Loss = 0.009, LR = 1.069182389937107e-05\nStep 6000: Loss = N/A, LR = N/A\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Step 6050: Loss = 0.0078, LR = 1.0364255765199162e-05\nStep 6100: Loss = 0.0084, LR = 1.0036687631027255e-05\nStep 6150: Loss = 0.0071, LR = 9.709119496855348e-06\nStep 6200: Loss = 0.0084, LR = 9.38155136268344e-06\nStep 6250: Loss = 0.0088, LR = 9.05398322851153e-06\nStep 6300: Loss = 0.0085, LR = 8.726415094339622e-06\nStep 6350: Loss = 0.0089, LR = 8.398846960167715e-06\nStep 6400: Loss = 0.0093, LR = 8.071278825995808e-06\nStep 6450: Loss = 0.0088, LR = 7.7437106918239e-06\nStep 6500: Loss = 0.0083, LR = 7.416142557651992e-06\nStep 6500: Loss = N/A, LR = N/A\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Step 6550: Loss = 0.0074, LR = 7.088574423480083e-06\nStep 6600: Loss = 0.0082, LR = 6.761006289308176e-06\nStep 6650: Loss = 0.0077, LR = 6.433438155136269e-06\nStep 6700: Loss = 0.0076, LR = 6.105870020964361e-06\nStep 6750: Loss = 0.0087, LR = 5.778301886792453e-06\nStep 6800: Loss = 0.0082, LR = 5.4507337526205454e-06\nStep 6850: Loss = 0.008, LR = 5.123165618448638e-06\nStep 6900: Loss = 0.0087, LR = 4.79559748427673e-06\nStep 6950: Loss = 0.0076, LR = 4.468029350104822e-06\nStep 7000: Loss = 0.0083, LR = 4.1404612159329145e-06\nStep 7000: Loss = N/A, LR = N/A\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Step 7050: Loss = 0.0082, LR = 3.8128930817610063e-06\nStep 7100: Loss = 0.0075, LR = 3.4853249475890986e-06\nStep 7150: Loss = 0.009, LR = 3.1577568134171913e-06\nStep 7200: Loss = 0.0084, LR = 2.830188679245283e-06\nStep 7250: Loss = 0.0075, LR = 2.5026205450733754e-06\nStep 7300: Loss = 0.008, LR = 2.1750524109014676e-06\nStep 7350: Loss = 0.0082, LR = 1.8474842767295599e-06\nStep 7400: Loss = 0.0078, LR = 1.519916142557652e-06\nStep 7450: Loss = 0.0072, LR = 1.1923480083857442e-06\nStep 7500: Loss = 0.0089, LR = 8.647798742138365e-07\nStep 7500: Loss = N/A, LR = N/A\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Step 7550: Loss = 0.0091, LR = 5.372117400419287e-07\nStep 7600: Loss = 0.0092, LR = 2.09643605870021e-07\nStep 7632: Loss = N/A, LR = N/A\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"pip install sacrebleu\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T10:59:36.235783Z","iopub.execute_input":"2025-04-12T10:59:36.236153Z","iopub.status.idle":"2025-04-12T10:59:40.280515Z","shell.execute_reply.started":"2025-04-12T10:59:36.236096Z","shell.execute_reply":"2025-04-12T10:59:40.279282Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: sacrebleu in /usr/local/lib/python3.10/dist-packages (2.5.1)\nRequirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (3.1.1)\nRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2024.11.6)\nRequirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.26.4)\nRequirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (5.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->sacrebleu) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->sacrebleu) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->sacrebleu) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->sacrebleu) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->sacrebleu) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import torch\n\nsample = eval_dataset[0]\ninput_text = tokenizer.decode(sample[\"input_ids\"], skip_special_tokens=True)\ntrue_output = tokenizer.decode(sample[\"labels\"], skip_special_tokens=True)\n\n\nmodel.eval()\nwith torch.no_grad():\n    pred_ids = model.generate(torch.tensor(sample[\"input_ids\"]).unsqueeze(0).to(model.device))\n    predicted_text = tokenizer.decode(pred_ids[0], skip_special_tokens=True)\n\nprint(\"Input Text:\", input_text)\nprint(\"Expected Output:\", true_output)\nprint(\"Model Prediction:\", predicted_text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T11:04:07.006834Z","iopub.execute_input":"2025-04-12T11:04:07.007170Z","iopub.status.idle":"2025-04-12T11:04:07.181911Z","shell.execute_reply.started":"2025-04-12T11:04:07.007144Z","shell.execute_reply":"2025-04-12T11:04:07.181006Z"}},"outputs":[{"name":"stdout","text":"Input Text: fix grammar: Things is improving in Algeria.\nExpected Output: Things are improving in Algeria.\nModel Prediction: Things are improving in Algeria.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"!pip install evaluate\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T11:04:35.506583Z","iopub.execute_input":"2025-04-12T11:04:35.506877Z","iopub.status.idle":"2025-04-12T11:04:39.334164Z","shell.execute_reply.started":"2025-04-12T11:04:35.506855Z","shell.execute_reply":"2025-04-12T11:04:39.333035Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.3.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.12.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.29.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.17.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.11.12)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2025.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.3\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import evaluate\nimport torch\nfrom transformers import GenerationConfig\nfrom tqdm import tqdm  \nimport random\n\neval_dataset_list = list(eval_dataset)\n\neval_dataset_sampled = random.sample(eval_dataset_list, 1000)\n\nbleu = evaluate.load(\"sacrebleu\")\n\n\ngeneration_config = GenerationConfig(\n    max_length=128,\n    num_beams=5,\n    early_stopping=True,\n    decoder_start_token_id=tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n)\n\n\nmodel.eval()\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Evaluation function\ndef compute_metrics_on_dataset(model, tokenizer, eval_dataset):\n    decoded_preds = []\n    decoded_labels = []\n    total_examples = len(eval_dataset)\n    print(f\"Total number of examples: {total_examples}\")\n\n    \n    for i, example in enumerate(tqdm(eval_dataset, desc=\"Evaluating\", total=total_examples)):  \n        input_ids = torch.tensor(example[\"input_ids\"]).unsqueeze(0).to(device)\n        label_ids = example[\"labels\"]\n\n    \n        with torch.no_grad():\n            generated_ids = model.generate(\n                input_ids,\n                **generation_config.to_dict()\n            )\n\n        \n        pred_str = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n        label_str = tokenizer.decode(label_ids, skip_special_tokens=True)\n\n    \n        decoded_preds.append(pred_str)\n        decoded_labels.append(label_str)\n\n    \n    bleu_score = bleu.compute(predictions=decoded_preds, references=[[lbl] for lbl in decoded_labels])[\"score\"]\n\n    \n    exact_matches = sum(1 for pred, gt in zip(decoded_preds, decoded_labels)\n                        if pred.strip().lower() == gt.strip().lower())\n    accuracy = (exact_matches / len(decoded_labels)) * 100\n\n    return {\"exact_match\": accuracy, \"bleu_score\": bleu_score}\n\n# Run evaluation\nmetrics = compute_metrics_on_dataset(model, tokenizer, eval_dataset_sampled)\n\nprint(f\"Exact Match Accuracy: {metrics['exact_match']:.2f}%\")\nprint(f\"BLEU Score: {metrics['bleu_score']:.2f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T11:37:39.939230Z","iopub.execute_input":"2025-04-12T11:37:39.939541Z","iopub.status.idle":"2025-04-12T12:20:00.222818Z","shell.execute_reply.started":"2025-04-12T11:37:39.939519Z","shell.execute_reply":"2025-04-12T12:20:00.221929Z"}},"outputs":[{"name":"stdout","text":"Total number of examples: 1000\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 1000/1000 [42:16<00:00,  2.54s/it]","output_type":"stream"},{"name":"stdout","text":"Exact Match Accuracy: 24.90%\nBLEU Score: 40.44\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":36}]}